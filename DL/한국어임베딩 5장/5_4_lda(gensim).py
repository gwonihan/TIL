# -*- coding: utf-8 -*-
"""5-4.LDA(gensim).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zGWT5ML_kXkmBaZnLuZRgeT04dZCliF8
"""

# Latent Dirichlet Allocation (LDA) using gensim
import numpy as np
import re
import pickle
from nltk.corpus import stopwords
from gensim import corpora
from gensim.models.ldamodel import LdaModel as LDA
from sklearn.datasets import fetch_20newsgroups
import nltk

nltk.download('stopwords')

# news data를 읽어온다.
news_data = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))

# 첫 번째 news를 조회해 본다.
news = news_data.data
print(len(news))
print(news[0])

# news 별로 분류된 target을 확인해 본다.
print(news_data.target_names)
print(len(news_data.target_names))

# preprocessing.
# 1. 영문자가 아닌 문자를 모두 제거한다.
news1 = [re.sub("[^a-zA-Z]", " ", x) for x in news]

# 2. 불용어를 제거하고, 모든 단어를 소문자로 변환하고, 길이가 3 이하인 
# 단어를 제거한다
stop_words = stopwords.words('english')
news2 = []
for doc in news1:
    doc1 = []
    for w in doc.split():
        w = w.lower()
        if len(w) > 3 and w not in stop_words:
            doc1.append(w)
    news2.append(doc1)
    
print(news2[0])

# doc2bow 생성
vocab = corpora.Dictionary(news2)
print(dict(list(vocab.items())[:10]))

news_bow = [vocab.doc2bow(s) for s in news2]
print(news_bow[0])

# Latent Dirichlet Allocation (LDA)
model = LDA(news_bow, num_topics = len(news_data.target_names), id2word=vocab, minimum_probability=0.001)

# 문서 별 Topic 번호를 확인한다. (문서 10개만 확인)
doc_topic = model.get_document_topics(news_bow)
np.array(doc_topic[0])

for i in range(10):
    dp = np.array(doc_topic[i])
    most_likely_topic = int(dp[np.argmax(dp[:, 1]), 0])
    print('문서-{:d} : topic = {:d}'.format(i, most_likely_topic))

# topic_term 행렬에서 topic 별로 중요 단어를 표시한다
topic_term = model.get_topic_terms(0, topn=10)
topic_term

for i in range(len(news_data.target_names)):
    topic_term = model.get_topic_terms(i, topn=10)
    idx = [idx for idx, score in topic_term]
    print('토픽-{:2d} : '.format(i+1), end='')
    for n in idx:
        print('{:s} '.format(vocab[n]), end='')
    print()

# 문서별로 분류된 코드를 확인해 본다.
# x, y : 문서 번호
def checkTopic(x, y):
    print("문서 %d의 topic = %s" % (x, news_data.target_names[news_data.target[x]]))
    print("문서 %d의 topic = %s" % (y, news_data.target_names[news_data.target[y]]))

checkTopic(2, 5)
checkTopic(7, 9)

