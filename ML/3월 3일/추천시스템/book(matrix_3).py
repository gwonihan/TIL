# -*- coding: utf-8 -*-
"""book(matrix_3).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tMff4eZtI72YBqp32_alQR4dgE1QO2jS
"""

# 행렬 분해를 이용한 잠재 요인 협업 필터링
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
import numba as nb

# Book 데이터를 읽어온다. 데이터 url : https://www.kaggle.com/arashnic/book-recommendation-dataset
DATA_PATH = '/content/drive/My Drive/Colab Notebooks/data/'
books = pd.read_csv(DATA_PATH + 'book/Books.csv')[['ISBN', 'Book-Title', 'Image-URL-M']]
ratings = pd.read_csv(DATA_PATH + 'book/Ratings.csv')
books.shape, ratings.shape

ratings.head()

# 데이터가 많아서 pivot_table()에서 메모리 에러가 발생한다.
# 일단 rating = 0을 제외하자.
# rating = 0은 무엇을 의미하는가? NaN 하고는 무엇이 다른가?
# 향후 deep learning에서는 pivoting을 하지 않으므로 'no problem'
ratings = ratings[ratings['Book-Rating'] > 0]

# 책을 한,두 권만 읽은 user들도 많다. 
# 10권 이하로 읽은 user들은 추천 대상에서 제외해 보자.
value_counts = ratings['User-ID'].value_counts()
to_remove = value_counts[value_counts <= 10].index
ratings = ratings[~ratings['User-ID'].isin(to_remove)]

# 책도 5명 이하가 본 책은 제외하자. 대중적이지 않은 책일 것임.
value_counts = ratings['ISBN'].value_counts()
to_remove = value_counts[value_counts <= 5].index
ratings = ratings[~ratings['ISBN'].isin(to_remove)]

ratings.shape

ratings.head()

print('user 수 =', len(set(ratings['User-ID'])))
print('book 개수 =', len(set(ratings['ISBN'])))
print('user number = {} ~ {}'.format(ratings['User-ID'].min(), ratings['User-ID'].max()))
print('book number = {} ~ {}'.format(ratings['ISBN'].min(), ratings['ISBN'].max()))

# rating의 scale 조정. 1 ~ 10 ==> 0.1 ~ 1.0
max_rating = ratings['Book-Rating'].max()
ratings['Book-Rating'] /= max_rating

# User-ID와 ISBN에 순차적인 id를 다시 부여한다.
user_enc = LabelEncoder()
item_enc = LabelEncoder()

ratings['User-ID'] = user_enc.fit_transform(ratings['User-ID'])
ratings['ISBN'] = item_enc.fit_transform(ratings['ISBN'])
ratings.head()

print('user 수 =', len(set(ratings['User-ID'])))
print('movie 개수 =', len(set(ratings['ISBN'])))
print('user number = {} ~ {}'.format(ratings['User-ID'].min(), ratings['User-ID'].max()))
print('movie number = {} ~ {}'.format(ratings['ISBN'].min(), ratings['ISBN'].max()))

# pivoting
UR = np.array(ratings.pivot_table('Book-Rating', index='User-ID', columns='ISBN'))

# number of users and items
N_ROW = UR.shape[0]
N_COL = UR.shape[1]
N_ROW, N_COL

#@title 행렬분해코드
@nb.jit
# SGD로 행렬 F, B를 업데이트한다.
def update_matrix(R, F, B, a, r):
    for i in range(N_ROW):
        for j in range(N_COL):
            if np.isnan(R[i, j]) != True:  # nan이 아니면
                # error 항을 계산한다.
                eij = R[i, j] - np.dot(F[i, :], B[j, :])
    
                # update F, B
                F[i, :] += a * (eij * B[j, :] - r * F[i, :])
                B[j, :] += a * (eij * F[i, :] - r * B[j, :])

@nb.jit
# NaN이 포함된 행렬의 mean_squared_error를 계산한다.
# 행렬 x에는 NaN이 포함돼 있다. y에는 없다.
def mse_skip_nan(x, y):
    mse = 0.0
    cnt = 0
    for i in range(x.shape[0]):
        for j in range(x.shape[1]):
            if np.isnan(x[i, j]) != True:  # nan이 아니면
                mse += (x[i, j] - y[i, j]) ** 2
                cnt += 1
    return mse / cnt

# SGD로 행렬을 F, B로 분해한다.
def factorize_matrix(matR, k, max_iter=1000, alpha=0.01, beta=0.01, err_limit=1e-4):
    # F, B를 random 초기화한다.
    F = np.random.rand(N_ROW, k)  # factor matrix
    B = np.random.rand(N_COL, k)  # beta matrix.
 
    old_err = 9999   # error 초깃값
    err_hist = []    # error history
    for step in range(max_iter):
        # F, B를 업데이트한다.
        update_matrix(matR, F, B, alpha, beta)
        
        # error를 계산하고 저장해 둔다.
        err = mse_skip_nan(matR, np.dot(F, B.T))
        err_hist.append(err)

        # early stopping
        if np.abs(old_err - err) < err_limit:
            break
        
        old_err = err
        
        if step % 10 == 0:
            print('{} : error={:.4f}'.format(step, err))

    if step >= max_iter - 1:
        print('max_iter={}번 동안 stop하지 못했습니다.'.format(max_iter))
        print('max_iter를 늘리거나 err_limit을 늘려야 합니다.')
        
    return F, B.T, err_hist

K = 10  # number of factors
F, B, err = factorize_matrix(UR, k=K, max_iter=100)
# 1분 17초 정도 걸렸음.

# 타겟 유저가 보지 않은 영화들에 대해 해당 유저가 부여할 rating을 추정한다.
user_id = 0   # target user
top_n = 10    # 추정 평점이 높은 상위 top_n개

# target user가 안 본 영화의 인덱스와 추정 rating
ER = np.dot(F, B)   # estimated R
unseen_idx = np.where(np.isnan(UR[user_id, :]))[0]
pred_R = ER[user_id, unseen_idx]

# target user에게 추천할 영화 리스트
# recom_idx = label encoding된 수치 배열임.
recom_idx = np.array(pred_R).argsort()[::-1][:top_n]

# recom_idx를 원래의 ISBN으로 환원한다.
recom_isbn = item_enc.inverse_transform(recom_idx)

# 추천 책들의 제목 대신 이미지를 표시한다.
from urllib.request import urlopen
import matplotlib.pyplot as plt
from PIL import Image

# 추천 대상 책의 이미지 url과 title (제목)을 뽑는다.
book_img_url = []
book_title = []
for x in recom_isbn:
    url = books[books['ISBN'] == x]['Image-URL-M'].values
    if len(url) > 0:  # 이미지 URL이 없는 경우는 제외했음.
        book_img_url.append(url[0])
        book_title.append(books[books['ISBN'] == x]['Book-Title'].values[0])

# 이미지를 표시한다.
fig, ax = plt.subplots(1, len(book_img_url),figsize=(16,2))

for i, (url, title) in enumerate(zip(book_img_url, book_title)):
    img = Image.open(urlopen(url))
    ax[i].imshow(img, aspect="auto")
    ax[i].set_title(title[:10] + '...')
    ax[i].axis('off')
plt.show()

# 책 제목을 표시한다.
print()
for i, title in enumerate(book_title):
    print('{:02d}.  {}'.format(i+1, title))

