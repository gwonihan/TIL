# -*- coding: utf-8 -*-
"""4-0.popcorn(EDA).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tZDK92DVlqGYE59KUZPsbKpQnyaPHsGW
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

# 학습 데이터를 읽어온다.
DATA_PATH = '/content/drive/My Drive/Colab Notebooks/data/'

train_data = pd.read_csv(DATA_PATH + 'labeledTrainData.tsv', header=0, sep='\t', quoting=3)
train_data.head()
# train_data.shape

print('전체 학습 데이터의 개수: {}'.format(len(train_data)))

train_length = train_data['review'].apply(len)
train_length.head()

plt.figure(figsize=(12,5))
plt.hist(train_length, bins=200, alpha=0.5, color='r', label='word')
# plt.yscale('log', nonposy='clip')
plt.title('Log-Histogram of length of reveiw')
plt.xlabel('Length of review')
plt.ylabel('Number of reveiw (log scale)')

print('리뷰 길이 최댓값: {}'.format(np.max(train_length)))
print('리뷰 길이 최솟값: {}'.format(np.min(train_length)))
print('리뷰 길이 평균값: {:.2f}'.format(np.mean(train_length)))
print('리뷰 길이 표준편차: {:.2f}'.format(np.std(train_length)))
print('리뷰 길이 중간값: {}'.format(np.median(train_length)))

# 사분위에 대한 경우는 0~100 스케일돼 있음.
print('리뷰 길이 제1사분위: {}'.format(np.percentile(train_length, 25)))
print('리뷰 길이 제3사분위: {}'.format(np.percentile(train_length, 75)))

plt.figure(figsize=(12,5))
plt.boxplot(train_length, labels=['counts'], showmeans=True)
plt.show()

from wordcloud import WordCloud
cloud = WordCloud(width=800, height=600).generate(" ".join(train_data['review']))
plt.figure(figsize=(20, 15))
plt.imshow(cloud)
plt.axis('off')

fig, axe = plt.subplots(ncols=1)
# fig.set_size_inches(6, 3)
sns.countplot(train_data['sentiment'])
plt.show()

print(train_data['sentiment'].value_counts())
print("\n긍정 리뷰 개수: {}".format(train_data['sentiment'].value_counts()[1]))
print("부정 리뷰 개수: {}".format(train_data['sentiment'].value_counts()[0]))

train_word_counts = train_data['review'].apply(lambda x: len(x.split(' ')))

plt.figure(figsize=(8, 4))
plt.hist(train_word_counts, bins=50, facecolor='r', label='train')
plt.title('Log-Histogram of word count in reveiw')
# plt.yscale('log', nonposy = 'clip')
plt.legend()
plt.xlabel('Number of words')
plt.ylabel('Number of reviews')
plt.show()

print('리뷰 단어 개수 최댓값: {}'.format(np.max(train_word_counts)))
print('리뷰 단어 개수 최솟값: {}'.format(np.min(train_word_counts)))
print('리뷰 단어 개수 평균값: {:.2f}'.format(np.mean(train_word_counts)))
print('리뷰 단어 개수 표준편차: {:.2f}'.format(np.std(train_word_counts)))
print('리뷰 단어 개수 중간값: {}'.format(np.median(train_word_counts)))

# 사분위에 대한 경우는 0~100 스케일돼 있음.
print('리뷰 단어 개수 제1사분위: {}'.format(np.percentile(train_word_counts, 25)))
print('리뷰 단어 개수 제3사분위: {}'.format(np.percentile(train_word_counts, 75)))

qmarks = np.mean(train_data['review'].apply(lambda x: '?' in x))
fullstop = np.mean(train_data['review'].apply(lambda x: '.' in x))
capital_first = np.mean(train_data['review'].apply(lambda x: x[0].isupper()))
capitals = np.mean(train_data['review'].apply(lambda x: max([y.isupper() for y in x])))
numbers = np.mean(train_data['review'].apply(lambda x: max([y.isdigit() for y in x])))

print('물음표가 있는 리뷰: {:.2f}'.format(qmarks * 100))
print('마침표가 있는 리뷰: {:.2f}'.format(fullstop * 100))
print('첫 글자가 대문자인 리뷰: {:.2f}'.format(capital_first * 100))
print('대문자가 있는 리뷰: {:.2f}'.format(capitals * 100))
print('숫자가 있는 리뷰: {:.2f}'.format(numbers * 100))

