# -*- coding: utf-8 -*-
"""tree_분기.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FEV3AzR0Z_j0bsD6Z4Po2EbU0SW8O-WB
"""

from sklearn.datasets import load_iris
import numpy as np
import pandas as pd

# iris 데이터를 읽어온다
iris = load_iris()

# iris['data']의 첫번째 feature만 사용하고, dataframe으로 저장한다.
df = pd.DataFrame(data= np.c_[iris['data'][:, 0], iris['target']], columns= ['x', 'y'])

# target의 class (label)는 0, 1, 2
labels = set(df['y'])

# 중복된 데이터를 제거하고 오름차순으로 정렬한다.
x_feat = list(set(df['x']))
x_feat.sort()

# split_points 리스트를 계산해 둔다 (분기 조건에 대한 후보들이다).
split_points = [np.mean([x_feat[i-1], x_feat[i]]) for i in range(1, len(x_feat))]

# Leaf node의 Gini index를 계산한다.
# L : left node, R : right node
def calculate_gini(L, R):
    n_left = np.sum(L)
    n_right = np.sum(R)
    n_total = n_left + n_right

    g_left = 1 - ((L / n_left) ** 2).sum()
    g_right = 1 - ((R / n_right) ** 2).sum()
    
    # weighted average
    gini = g_left * n_left / n_total + g_right * n_right / n_total
    return gini

# 모든 split_points에 대해 Gini index를 계산한다.
gini = []
for s in split_points:
    left = np.array(df[df['x'] <= s]['y']).astype('int')
    left_leaf = [np.sum(left == x) for x in labels]

    right = np.array(df[df['x'] > s]['y']).astype('int')
    right_leaf = [np.sum(right == x) for x in labels]

    gini.append(calculate_gini(left_leaf, right_leaf))

# split_points 중에 최적 point를 찾는다.
# Gini index가 가장 작은 point를 찾는다. 이 지점의 information gain이 가장 크다.
best = np.argmin(gini)
print("Best split point = {}".format(split_points[best]))

from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
import matplotlib.pyplot as plt

# sklearn으로 decision tree를 생성한다.
x_train = np.array(df['x']).reshape(-1, 1)
y_train = df['y']

# 최초의 분기만 확인하기 위해 max_depth = 1로 설정한다.
clf = DecisionTreeClassifier(max_depth=1)
clf.fit(x_train, y_train)

# 결과를 확인한다.
plt.figure(figsize=(12,4))
tree.plot_tree(clf, feature_names = ['x'], fontsize=12)
plt.show()

