# -*- coding: utf-8 -*-
"""DTree(optimal_depth).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nYcKwhdrhhqir2goWayBLGKpOaIxJpRV
"""

import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
import numpy as np

# iris 데이터를 읽어온다
iris = load_iris()

x_train, x_test, y_train, y_test = train_test_split(iris['data'], iris['target'], test_size=0.2)

# k를 변화시켜가면서 정확도를 측정해 본다
acc_test = []
acc_train = []
d_max = 30
for d in range(1, d_max):
    # KNN 으로 학습 데이터 세트를 학습한다.
    dt = DecisionTreeClassifier(max_depth=d)
    dt.fit(x_train, y_train)
    
    # 시험 데이터의 Feature에 대한 정확도
    y_pred = dt.predict(x_test)
    acc_test.append((y_test == y_pred).mean())
    
    # 학습 데이터의 Feature에 대한 정확도
    y_pred = dt.predict(x_train)
    acc_train.append((y_train == y_pred).mean())

    # 아래처럼해도 된다.
    # acc_test.append(knn.score(x_test, y_test))
    # acc_train.append(knn.score(x_train, y_train))

plt.figure(figsize=(8, 5))
plt.plot(acc_test, marker='o', label="Test Data")
plt.plot(acc_train, marker='o', label="Train Data")
plt.legend()
plt.xlabel("ma_depth")
plt.ylabel("Accuracy")
plt.xticks(np.arange(d_max), np.arange(1, d_max + 1))
plt.show()

opt_depth = np.argmax(acc_test)
opt_acc = acc_test[opt_depth]

print("optimal depth = {}, accuracy = {:.3f}".format(opt_depth + 1, opt_acc))

